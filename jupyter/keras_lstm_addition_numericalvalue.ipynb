{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "name": "keras-lstm-addition-numericalvalue.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This is derived and modified from keras-lstm-addition-text.ipynb"
      ],
      "metadata": {
        "id": "0u2-1JxtoklL"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSfFcGG131AT"
      },
      "source": [
        "import tensorflow\n",
        "from tensorflow import keras\n",
        "\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten\n",
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Dropout, Activation\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "import numpy as np"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make sure to check the version of TesorFlow and Kera. This is very important."
      ],
      "metadata": {
        "id": "x_BgGkeMqpzO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(tensorflow.__version__)\n",
        "print(keras.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PK4MQ546qLsI",
        "outputId": "287f0cc7-a658-4185-f666-ed3603b5bc27"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.7.0\n",
            "2.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This sample uses only label data ('y' data)."
      ],
      "metadata": {
        "id": "BrfLqEFMpXxz"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-k8nDcn31AX"
      },
      "source": [
        "from keras.datasets import mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YhlPaJM11XmN",
        "outputId": "79299b52-d7ea-4712-a9d7-59de473688cb"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQPfnrD131AZ",
        "outputId": "ceb1727f-136d-4cc4-fc4c-e60f1ddd5848",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# convert class vectors to binary class matrices\n",
        "num_classes = 10\n",
        "\n",
        "y_onehot_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_onehot_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "60000 train samples\n",
            "10000 test samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnNIcd1031Ab",
        "outputId": "3c9c6b7f-f791-4520-f61b-e1b9805f96ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(y_onehot_train[0])"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sequence_size = 2\n",
        "output_size = 19\n",
        "\n",
        "x_T = []\n",
        "y_T = []\n",
        "x_T_onehot=[]\n",
        "y_T_onehot=[]\n",
        "\n",
        "sampling_size=3\n",
        "batch_size = sampling_size\n",
        "\n",
        "x = x_train\n",
        "y = y_train\n",
        "y_onehot = y_onehot_train\n",
        "\n",
        "for _ in range(sequence_size):\n",
        "    y_onehot_batch=[]\n",
        "    y_batch=[]\n",
        "    for i in range(batch_size):\n",
        "        idx = np.random.randint(0, len(x))\n",
        "        # y batch\n",
        "        y_batch.append(y[idx])\n",
        "\n",
        "        # one hot encoding\n",
        "        y_onehot_batch.append(y_onehot[idx])\n",
        "\n",
        "        print(y[idx])\n",
        "        print(y_onehot[idx])\n",
        "\n",
        "    # x list of sequence\n",
        "    x_T.append(y_batch)\n",
        "    x_T_onehot.append(y_onehot_batch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HVg7SEOK0Zp_",
        "outputId": "aa69cc43-4362-4460-dca0-15384645314f"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            "4\n",
            "[0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            "9\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "5\n",
            "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            "0\n",
            "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "5\n",
            "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_T=np.asarray(x_T[0]) + np.asarray(x_T[1])\n",
        "print(y_T)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1WeefhrJ3DT9",
        "outputId": "28bc3220-18f3-4dac-f082-8f2d6d58d272"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[10  4 14]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_T[0])\n",
        "print(x_T[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kEeTpOPr3qjz",
        "outputId": "81fd9e50-014a-4236-9055-a291cb732d59"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[5, 4, 9]\n",
            "[5, 0, 5]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SdJK5lta31As"
      },
      "source": [
        "sequence_size = 2\n",
        "output_size = 19\n",
        "\n",
        "def sampling_data(x, y, y_onehot, sampling_size=50000):\n",
        "    x_T = []\n",
        "    y_T = []\n",
        "    x_T_onehot=[]\n",
        "    y_T_onehot=[]\n",
        "\n",
        "    batch_size = sampling_size\n",
        "    for _ in range(sequence_size):\n",
        "        y_onehot_batch=[]\n",
        "        y_batch=[]\n",
        "        for i in range(batch_size):\n",
        "            idx = np.random.randint(0, len(x))\n",
        "            # y batch\n",
        "            y_batch.append(y[idx])\n",
        "\n",
        "            # one hot encoding\n",
        "            y_onehot_batch.append(y_onehot[idx])\n",
        "\n",
        "            #print(y[idx])\n",
        "            #print(y_onehot[idx])\n",
        "\n",
        "        # x list of sequence\n",
        "        x_T.append(y_batch)\n",
        "        x_T_onehot.append(y_onehot_batch)\n",
        "\n",
        "    y_T = np.asarray(x_T[0]) + np.asarray(x_T[1])\n",
        "    #print(y_T)\n",
        "    #one hot encording\n",
        "    y_T_onehot = keras.utils.to_categorical(y_T, output_size)\n",
        "\n",
        "\n",
        "    return x_T,y_T,x_T_onehot, y_T_onehot"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZKdYLAH231Au"
      },
      "source": [
        "#x_T,y_T,x_T_onehot,y_T_onehot = sampling_data(x_train, y_train, y_onehot_train, 100)\n",
        "\n",
        "# Default sampling size is 50,000.\n",
        "x_T,y_T,x_T_onehot,y_T_onehot = sampling_data(x_train, y_train, y_onehot_train)"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_T_onehot = np.array(x_T_onehot)"
      ],
      "metadata": {
        "id": "hLkKZgPA5CzD"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WtpsQtiM31Aw"
      },
      "source": [
        "y_T_onehot = np.array(y_T_onehot)"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTykdyMD31A0",
        "outputId": "788e3115-219b-4c4b-87bd-92d890c59f40",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(x_T_onehot.shape)\n",
        "x_T_onehot = np.transpose(x_T_onehot, (1, 0, 2))\n",
        "print(np.shape(x_T_onehot))"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2, 50000, 10)\n",
            "(50000, 2, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.shape(y_T_onehot))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ASg6hWZu6Ea5",
        "outputId": "114dc564-1a0a-4f97-cc8c-744f851866cf"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(50000, 19)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eEEuoO9L31A2",
        "outputId": "ade7d72e-b75f-4526-c632-4df79fcc0255",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#from tensorflow.keras.models import Sequential\n",
        "#from keras.layers.core import Dense, Activation\n",
        "#from keras.layers.recurrent import LSTM\n",
        "#from keras.optimizers import Adam\n",
        "\n",
        "seq_length = 2\n",
        "n_in = 10\n",
        "n_hidden = 128\n",
        "n_out = 19\n",
        "\n",
        "model=Sequential()\n",
        "model.add(LSTM(units=n_hidden, input_shape=(seq_length, n_in)))\n",
        "model.add(Dense(units=n_out))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "optimizer = Adam(lr=0.001, beta_1=0.9, beta_2=0.999)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "#query = [[[1,0,0,0,0,0,0,0,0,0],[0,1,0,0,0,0,0,0,0,0]],[[0,1,0,0,0,0,0,0,0,0],[0,1,0,0,0,0,0,0,0,0]]]\n",
        "#answer = [[0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]]\n",
        "\n",
        "#query = np.array(query)\n",
        "#answer = np.array(answer)\n",
        "\n",
        "batch_size=20\n",
        "\n",
        "query = x_T_onehot\n",
        "answer = y_T_onehot\n",
        "\n",
        "model.fit(query, answer,\n",
        "          batch_size=batch_size,\n",
        "          epochs=10,\n",
        "          validation_split=0.1,\n",
        "          )\n",
        " \n"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "2250/2250 [==============================] - 11s 4ms/step - loss: 0.9345 - accuracy: 0.7508 - val_loss: 0.0825 - val_accuracy: 1.0000\n",
            "Epoch 2/10\n",
            "2250/2250 [==============================] - 9s 4ms/step - loss: 0.0234 - accuracy: 1.0000 - val_loss: 0.0055 - val_accuracy: 1.0000\n",
            "Epoch 3/10\n",
            "2250/2250 [==============================] - 9s 4ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 4/10\n",
            "2250/2250 [==============================] - 9s 4ms/step - loss: 6.2811e-04 - accuracy: 1.0000 - val_loss: 3.0178e-04 - val_accuracy: 1.0000\n",
            "Epoch 5/10\n",
            "2250/2250 [==============================] - 9s 4ms/step - loss: 1.7293e-04 - accuracy: 1.0000 - val_loss: 8.6616e-05 - val_accuracy: 1.0000\n",
            "Epoch 6/10\n",
            "2250/2250 [==============================] - 9s 4ms/step - loss: 5.0522e-05 - accuracy: 1.0000 - val_loss: 2.5881e-05 - val_accuracy: 1.0000\n",
            "Epoch 7/10\n",
            "2250/2250 [==============================] - 9s 4ms/step - loss: 1.5258e-05 - accuracy: 1.0000 - val_loss: 7.9911e-06 - val_accuracy: 1.0000\n",
            "Epoch 8/10\n",
            "2250/2250 [==============================] - 9s 4ms/step - loss: 4.7472e-06 - accuracy: 1.0000 - val_loss: 2.5152e-06 - val_accuracy: 1.0000\n",
            "Epoch 9/10\n",
            "2250/2250 [==============================] - 9s 4ms/step - loss: 1.5307e-06 - accuracy: 1.0000 - val_loss: 8.3067e-07 - val_accuracy: 1.0000\n",
            "Epoch 10/10\n",
            "2250/2250 [==============================] - 10s 4ms/step - loss: 5.1714e-07 - accuracy: 1.0000 - val_loss: 2.9242e-07 - val_accuracy: 1.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f62b7529ed0>"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VkmSO6gu31BB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0fdf929f-0c5e-4e43-8df5-b5bc229318b8"
      },
      "source": [
        "query = [[[0,0,1,0,0,0,0,0,0,0],[0,1,0,0,0,0,0,0,0,0]]]\n",
        "answer = model.predict(query)\n",
        "print (np.argmax(answer))\n",
        "\n",
        "query = [[[0,0,0,0,0,1,0,0,0,0],[0,0,0,0,0,0,0,0,1,0]]]\n",
        "answer = model.predict(query)\n",
        "print (np.argmax(answer))"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n",
            "13\n"
          ]
        }
      ]
    }
  ]
}